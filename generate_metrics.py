"""
æ–‡ä»¶å: generate_metrics.py

æè¿°:
    è¯¥è„šæœ¬ç”¨äºåœ¨ç»™å®šå‚æ•°é…ç½®å’Œé€šä¿¡ä¼˜å…ˆçº§ç»„åˆçš„æƒ…å†µä¸‹ï¼Œ
    è°ƒç”¨æµæ°´çº¿æ¨¡æ‹Ÿå™¨ï¼ˆ1F1B æˆ– GPipeï¼Œå•/åŒé€šé“ï¼‰ï¼Œ
    ç”ŸæˆåŒ…æ‹¬è®­ç»ƒæ€»æ—¶é—´ã€è®¡ç®—ä¸é€šä¿¡æ—¶é—´å æ¯”ã€
    é€šä¿¡ååé‡ã€é€šä¿¡å»¶è¿ŸåŠèµ„æºåˆ©ç”¨ç‡ç­‰å¤šé¡¹æ€§èƒ½æŒ‡æ ‡ã€‚

    ä¸ data_generator.py ç±»ä¼¼ï¼Œè¯¥è„šæœ¬éå†ç»™å®š JSON é…ç½®ä¸­çš„æ‰€æœ‰å‚æ•°ç»„åˆã€
    ä¸åŒçš„ä¸»åŠ¨ç‹¬å åœºæ™¯ä»¥åŠå…±äº«ä¼˜å…ˆçº§æ’åˆ—ï¼Œé€šè¿‡è°ƒç”¨
    schedule_visualizer_* æ¨¡å—çš„ calculate_full_pipeline_schedule å‡½æ•°
    è·å–æ¨¡æ‹Ÿè°ƒåº¦ç»“æœï¼Œå¹¶ä»ä¸­æå–è¯¦ç»†æŒ‡æ ‡ã€‚

ç”¨æ³•ç¤ºä¾‹:
    python generate_metrics.py --config my_experiment_config.json \
        --pipeline 1f1b --simulator single_channel \
        --step 0.1 --output outputs/data/metrics.csv \
        --enable-recv-congestion

    å…¶ä¸­:
        --config æŒ‡å®šå‚æ•°é…ç½®æ–‡ä»¶;
        --pipeline é€‰æ‹© "1f1b" æˆ– "gpipe";
        --simulator é€‰æ‹© "single_channel" æˆ– "dual/duel_channel";
        --step è®¾ç½®å…±äº«ä¼˜å…ˆçº§æ‰«ææ­¥é•¿;
        --enable-recv-congestion åœ¨ 1f1b å•é€šé“åœºæ™¯ä¸‹å¯ç”¨æ¥æ”¶ç«¯æ‹¥å¡æ§åˆ¶;
        --output æŒ‡å®šè¾“å‡º CSV æ–‡ä»¶ã€‚

è¾“å‡º CSV åˆ—åŒ…å«:
    n, sync_freq, fwd_len, bwd_len, prop_len, sync_base_len, fwd_impact, bwd_impact,
    p_fwd_prop, p_grad_prop, p_grad_sync, total_time,
    compute_ratio, comm_ratio, avg_throughput, avg_latency,
    compute_utilization, comm_utilization

ä½œè€…: ChatGPT
æ—¥æœŸ: 2025-08-10
"""

import argparse
import importlib
import inspect
import json
import multiprocessing
import numpy as np
import os
import datetime
from itertools import product
from typing import Dict, List, Tuple


# ---------- å·¥å…·å‡½æ•° ----------
def generate_scan_values(config_value):
    """ä»é…ç½®é¡¹ç”Ÿæˆæ‰«æåˆ—è¡¨ï¼ŒåŒ data_generator.py"""
    if isinstance(config_value, list):
        return config_value
    elif isinstance(config_value, dict):
        steps = int(round((config_value['stop'] - config_value['start']) / config_value.get('step', 1.0))) + 1
        return np.linspace(config_value['start'], config_value['stop'], steps)
    return [config_value]


def compute_network_load(blocks: List[Dict]) -> Tuple[List[float], Dict[str, List[float]]]:
    """
    æ ¹æ®è°ƒåº¦ç»“æœ blocksï¼Œç»Ÿè®¡å•é€šé“åœºæ™¯ä¸‹é€šä¿¡å¸¦å®½éšæ—¶é—´çš„å ç”¨ã€‚
    è¿”å›æ—¶é—´ç‚¹åˆ—è¡¨ times å’Œå„é€šä¿¡ç±»å‹çš„å¸¦å®½å ç”¨ loadsã€‚
    - loads['total'] ä¸ºåœ¨è¯¥æ—¶é—´æ®µå†…æ‰€æœ‰é€šä¿¡ä»»åŠ¡çš„å¸¦å®½å’Œ
    - loads['fwd_prop'], loads['grad_prop'], loads['grad_sync'] åˆ†åˆ«å¯¹åº”ä¸åŒé€šä¿¡ä»»åŠ¡
    """
    comm_types = {"fwd_prop", "grad_prop", "grad_sync"}
    # æ”¶é›†æ‰€æœ‰é€šä¿¡ç›¸å…³ä»»åŠ¡çš„è¾¹ç•Œæ—¶é—´
    time_points = sorted({float(b['start']) for b in blocks if b['type'] in comm_types} |
                         {float(b['end']) for b in blocks if b['type'] in comm_types})
    if len(time_points) < 2:
        return [], {'total': [], 'fwd_prop': [], 'grad_prop': [], 'grad_sync': []}
    loads = {'total': [], 'fwd_prop': [], 'grad_prop': [], 'grad_sync': []}
    for i in range(len(time_points) - 1):
        t0, t1 = time_points[i], time_points[i + 1]
        total = fwd = grad = sync = 0.0
        for b in blocks:
            if b['type'] in comm_types and b['start'] <= t0 and b['end'] >= t1:
                # b['width'] è¡¨ç¤ºå ç”¨çš„å¸¦å®½ä»½é¢ï¼Œè‹¥ä¸å­˜åœ¨åˆ™è§†ä¸º1
                w = float(b.get('width', 1.0))
                total += w
                if b['type'] == 'fwd_prop':
                    fwd += w
                elif b['type'] == 'grad_prop':
                    grad += w
                elif b['type'] == 'grad_sync':
                    sync += w
        loads['total'].append(total)
        loads['fwd_prop'].append(fwd)
        loads['grad_prop'].append(grad)
        loads['grad_sync'].append(sync)
    return time_points[:-1], loads


def compute_metrics(blocks: List[Dict]) -> Dict[str, float]:
    """
    æ ¹æ®è°ƒåº¦å—åˆ—è¡¨è®¡ç®—å„é¡¹æŒ‡æ ‡ã€‚
    è¿”å›:
        dict åŒ…å« total_time, compute_ratio, comm_ratio, avg_throughput, avg_latency,
        compute_utilization, comm_utilization
    """
    if not blocks:
        return {
            'total_time': 0.0,
            'compute_ratio': 0.0,
            'comm_ratio': 0.0,
            'avg_throughput': 0.0,
            'avg_latency': 0.0,
            'compute_utilization': 0.0,
            'comm_utilization': 0.0,
        }
    # æ€»è®­ç»ƒæ—¶é—´ä¸ºæ‰€æœ‰ä»»åŠ¡çš„ç»“æŸæ—¶é—´æœ€å¤§å€¼
    total_time = max(float(b['end']) for b in blocks)
    # è®¡ç®—é€šé“æ€»æ—¶é•¿ (æ‰€æœ‰ GPU) å’Œé€šä¿¡é€šé“æ€»æ—¶é•¿
    compute_time = sum((float(b['end']) - float(b['start'])) for b in blocks if b['type'] in ('forward', 'backward'))
    comm_time = sum((float(b['end']) - float(b['start'])) for b in blocks if b['type'] in ('fwd_prop', 'grad_prop', 'grad_sync', 'param_sync'))
    # è®¡ç®—ä¸é€šä¿¡æ—¶é—´å æ¯”: ç›¸å¯¹äºæ‰€æœ‰è®¡ç®—+é€šä¿¡ä»»åŠ¡çš„æ€»å’Œ
    total_compute_comm = compute_time + comm_time
    if total_compute_comm > 0:
        compute_ratio = compute_time / total_compute_comm
        comm_ratio = comm_time / total_compute_comm
    else:
        compute_ratio = 0.0
        comm_ratio = 0.0
    # é€šä¿¡ååé‡: æŒ‰æ—¶é—´ç‰‡å¹³å‡ aggregated bandwidth ä½¿ç”¨ç‡
    times, loads = compute_network_load(blocks)
    if loads['total']:
        avg_throughput = float(np.mean(loads['total']))
    else:
        avg_throughput = 0.0
    # é€šä¿¡å»¶è¿Ÿ: å¹³å‡æ¯ä¸ªé€šä¿¡ä»»åŠ¡æŒç»­æ—¶é—´
    comm_latencies = [float(b['end']) - float(b['start']) for b in blocks if b['type'] in ('fwd_prop', 'grad_prop', 'grad_sync')]
    avg_latency = float(np.mean(comm_latencies)) if comm_latencies else 0.0
    # æ¨æ–­ GPU æ•°é‡
    # å— id æ ¼å¼: (task_type, micro_batch_index, stage_index)
    stage_indices = [b['id'][2] for b in blocks if isinstance(b['id'], tuple) and len(b['id']) >= 3]
    num_gpus = max(stage_indices) + 1 if stage_indices else 1
    # è®¡ç®—è®¡ç®—èµ„æºåˆ©ç”¨ç‡: æ‰€æœ‰è®¡ç®—ä»»åŠ¡æŒç»­æ—¶é—´ / (num_gpus * total_time)
    compute_utilization = compute_time / (num_gpus * total_time) if total_time > 0 else 0.0
    # è®¡ç®—é€šä¿¡èµ„æºåˆ©ç”¨ç‡: å¯¹æ¯ä¸ªé€šä¿¡ä»»åŠ¡ä¹˜ä»¥å ç”¨å¸¦å®½å®½åº¦ï¼Œå†é™¤ä»¥ (num_gpus * total_time)
    comm_utilization_sum = sum(float(b.get('width', 1.0)) * (float(b['end']) - float(b['start']))
                              for b in blocks if b['type'] in ('fwd_prop', 'grad_prop', 'grad_sync'))
    comm_utilization = comm_utilization_sum / (num_gpus * total_time) if total_time > 0 else 0.0
    return {
        'total_time': total_time,
        'compute_ratio': compute_ratio,
        'comm_ratio': comm_ratio,
        'avg_throughput': avg_throughput,
        'avg_latency': avg_latency,
        'compute_utilization': compute_utilization,
        'comm_utilization': comm_utilization
    }


def run_single_simulation_metrics(args_tuple) -> str:
    """
    æ ¸å¿ƒå·¥ä½œå‡½æ•°ï¼Œç”¨äºå¹¶è¡Œè®¡ç®—ã€‚
    è¾“å…¥å…ƒç»„: (sim_module_name, params, exclusive_config, priority_config, header_params)
    è¾“å‡º: ä¸€è¡Œ CSV å­—ç¬¦ä¸²
    """
    sim_module_name, current_params, exclusive_config, priority_config, header_params = args_tuple
    sim = importlib.import_module(sim_module_name)

    base_lengths = {
        'forward': current_params['fwd_len'],
        'backward': current_params['bwd_len'],
        'fwd_prop': current_params['prop_len'],
        'grad_prop': current_params['prop_len'],
        'grad_sync': current_params['sync_base_len'],
        'param_sync': 1
    }

    # æ ¹æ®ç‹¬å ç­‰çº§æ›´æ–°ä»»åŠ¡ç‹¬å é…ç½®å’Œå…±äº«æƒé‡
    final_priorities = dict(sim.default_priorities)
    final_exclusive_tiers = dict(sim.default_exclusive_tiers)
    for task, tier in exclusive_config.items():
        final_exclusive_tiers[task] = tier
    # æ ¹æ®ä¼˜å…ˆçº§é…ç½®åˆ†é…å…±äº«æƒé‡
    epsilon = 1e-9
    sharing_tasks = [t for t, tier in final_exclusive_tiers.items() if tier is None]
    if sharing_tasks:
        safe_priorities = {t: priority_config.get(t, 0) if priority_config.get(t, 0) > 0 else epsilon for t in sharing_tasks}
        total_safe_p = sum(safe_priorities.values())
        if total_safe_p > 1e-9:
            for task in sharing_tasks:
                final_priorities[task] = safe_priorities[task] / total_safe_p

    # å¯é€‰çš„æ¥æ”¶ç«¯æ‹¥å¡æ§åˆ¶å¼€å…³
    extra_kwargs = {}
    try:
        sig = inspect.signature(sim.calculate_full_pipeline_schedule)
        enable_cc = os.environ.get('ENABLE_RECV_CONGESTION', '0') == '1'
        if 'use_recv_congestion' in sig.parameters:
            # ä»…å¯¹ 1f1b å•é€šé“æœ‰æ•ˆ
            extra_kwargs['use_recv_congestion'] = enable_cc
    except Exception:
        pass

    # è°ƒç”¨æ¨¡æ‹Ÿå™¨è·å–è°ƒåº¦ç»“æœ
    result = sim.calculate_full_pipeline_schedule(
        n=current_params['n'],
        num_gpus=4,
        is_ideal=False,
        lengths=base_lengths,
        priorities=final_priorities,
        exclusive_tiers=final_exclusive_tiers,
        fwd_impact=current_params['fwd_impact'],
        bwd_impact=current_params['bwd_impact'],
        sync_solo_w=1.0,
        sync_freq=current_params['sync_freq'],
        **extra_kwargs
    )
    # result æ˜¯ä¸‰å…ƒç»„ (blocks, total_time, throttled_ids)
    blocks = result[0] if isinstance(result, tuple) else result
    metrics = compute_metrics(blocks)

    # è¾“å‡ºç”¨çš„å®é™…ä¼˜å…ˆçº§å€¼ï¼šå¦‚æœæ˜¯ç‹¬å ä»»åŠ¡ï¼Œç”¨å­—æ¯ï¼Œå¦åˆ™ç”¨æµ®ç‚¹æ•°
    output_priorities = {}
    for task in ['fwd_prop', 'grad_prop', 'grad_sync']:
        if exclusive_config.get(task) is not None:
            output_priorities[task] = exclusive_config[task]
        else:
            output_priorities[task] = priority_config.get(task, 0.0)
    # ç»„åˆ CSV è¡Œ
    values = [current_params.get(h) for h in header_params]
    values.extend([
        output_priorities['fwd_prop'],
        output_priorities['grad_prop'],
        output_priorities['grad_sync'],
        f"{metrics['total_time']:.4f}",
        f"{metrics['compute_ratio']:.4f}",
        f"{metrics['comm_ratio']:.4f}",
        f"{metrics['avg_throughput']:.4f}",
        f"{metrics['avg_latency']:.4f}",
        f"{metrics['compute_utilization']:.4f}",
        f"{metrics['comm_utilization']:.4f}"
    ])
    return ','.join(map(str, values)) + '\n'


def load_param_grid(json_path: str) -> Dict[str, List]:
    """ä» JSON æ–‡ä»¶åŠ è½½å‚æ•°ç½‘æ ¼ï¼Œè¿”å›å­—å…¸"""
    with open(json_path, 'r') as f:
        return json.load(f)


def generate_metrics(simulator_module_name: str, output_file: str, param_grid: Dict[str, List], priority_step: float) -> None:
    """
    æ‰«ææ‰€æœ‰å‚æ•°ç»„åˆå’Œä¼˜å…ˆçº§ç»„åˆï¼Œè®¡ç®—æŒ‡æ ‡å¹¶å†™å…¥ CSVã€‚
    ç±»ä¼¼äº data_generator.generate_data_for_fittingï¼Œä½†åŒ…å«æ›´å¤šæŒ‡æ ‡ã€‚
    """
    tasks = ['fwd_prop', 'grad_prop', 'grad_sync']
    # å®šä¹‰ç‹¬å åœºæ™¯ã€‚ä»…è€ƒè™‘å•ç‹¬æå‡æŸä¸€é€šä¿¡ä»»åŠ¡ä¸ºç‹¬å ã€‚
    exclusive_scenarios = [
        {'fwd_prop': None, 'grad_prop': None, 'grad_sync': None},
        {'fwd_prop': 'a', 'grad_prop': None, 'grad_sync': None},
        {'fwd_prop': None, 'grad_prop': 'a', 'grad_sync': None},
    ]
    param_names = list(param_grid.keys())
    param_values = [generate_scan_values(param_grid[k]) for k in param_names]
    all_param_combos_raw = list(product(*param_values))
    # è¿‡æ»¤æ‰ sync_freq > n çš„ç»„åˆ
    param_combinations = []
    for combo in all_param_combos_raw:
        param_dict = dict(zip(param_names, combo))
        if param_dict['sync_freq'] <= param_dict['n']:
            param_combinations.append(param_dict)
    all_jobs = []
    header_params = param_names
    for params in param_combinations:
        for exclusive_config in exclusive_scenarios:
            sharing_tasks = [t for t, tier in exclusive_config.items() if tier is None]
            num_sharing = len(sharing_tasks)
            priority_configs_for_scenario = []
            if num_sharing > 0:
                step_values = np.arange(0, 1.0 + priority_step, priority_step)
                for p_values in product(step_values, repeat=num_sharing):
                    if abs(sum(p_values) - 1.0) < 1e-9:
                        priority_config = {task: round(p, 4) for task, p in zip(sharing_tasks, p_values)}
                        priority_configs_for_scenario.append(priority_config)
            else:
                priority_configs_for_scenario.append({})
            for priority_config in priority_configs_for_scenario:
                full_priority_config = {t: 0.0 for t in tasks}
                full_priority_config.update(priority_config)
                all_jobs.append((simulator_module_name, params, exclusive_config, full_priority_config, header_params))
    total_runs = len(all_jobs)
    print(f"ğŸ” é¢„è®¡æ€»æŒ‡æ ‡è®¡ç®—æ¬¡æ•°: {total_runs}")
    # æ‰§è¡Œå¹¶è¡Œè®¡ç®—
    try:
        results = []
        num_workers = max(1, os.cpu_count() - 1)
        print(f"ğŸ§® ä½¿ç”¨ {num_workers} ä¸ªæ ¸å¿ƒè¿›è¡ŒæŒ‡æ ‡è®¡ç®—...")
        with multiprocessing.Pool(processes=num_workers) as pool:
            for line in pool.imap_unordered(run_single_simulation_metrics, all_jobs):
                results.append(line)
        # æŒ‰æ€»æ—¶é—´å‡åºæ’åº
        results.sort(key=lambda l: float(l.strip().split(',')[len(header_params) + 3]))  # total_time åˆ—ç´¢å¼•
        # å†™å…¥æ–‡ä»¶
        with open(output_file, 'w') as f:
            header = header_params + [
                'p_fwd_prop', 'p_grad_prop', 'p_grad_sync',
                'total_time', 'compute_ratio', 'comm_ratio',
                'avg_throughput', 'avg_latency',
                'compute_utilization', 'comm_utilization'
            ]
            f.write(','.join(header) + '\n')
            for line in results:
                f.write(line)
        print(f"âœ… æŒ‡æ ‡æ•°æ®å·²ä¿å­˜åˆ°: {output_file}")
    except Exception as e:
        print(f"âš ï¸ ç”ŸæˆæŒ‡æ ‡æ•°æ®æ—¶å‡ºé”™: {e}")


def main():
    parser = argparse.ArgumentParser(description="åŸºäºæµæ°´çº¿æ¨¡æ‹Ÿç”Ÿæˆé€šä¿¡/è®¡ç®—æŒ‡æ ‡æ•°æ®")
    parser.add_argument('--config', required=True, help='å‚æ•°é…ç½®æ–‡ä»¶ (JSON)')
    parser.add_argument('--pipeline', choices=['1f1b', 'gpipe'], default='1f1b', help='é€‰æ‹©æµæ°´çº¿è°ƒåº¦ç­–ç•¥')
    parser.add_argument('--simulator', choices=['single_channel', 'dual_channel', 'duel_channel'], default='single_channel', help='é€šä¿¡é€šé“ç±»å‹')
    parser.add_argument('--step', type=float, default=0.1, help='å…±äº«ä¼˜å…ˆçº§æ‰«ææ­¥é•¿')
    parser.add_argument('--output', type=str, default=None, help='è¾“å‡º CSV æ–‡ä»¶')
    parser.add_argument('--enable-recv-congestion', action='store_true', help='åœ¨ 1f1b å•é€šé“åœºæ™¯ä¸‹å¯ç”¨æ¥æ”¶ç«¯æ‹¥å¡æ§åˆ¶')
    args = parser.parse_args()
    # å¤„ç† dual/duel åç§°å·®å¼‚
    sim_name = args.simulator
    if sim_name == 'dual_channel':
        sim_name = 'duel_channel'
    sim_module_name = f'schedule_visualizer_{args.pipeline}_{sim_name}'
    # æ£€æŸ¥æ¨¡å—æ˜¯å¦å­˜åœ¨
    try:
        importlib.import_module(sim_module_name)
    except ImportError as e:
        print(f"âŒ æ— æ³•å¯¼å…¥æ¨¡æ‹Ÿå™¨æ¨¡å— {sim_module_name}: {e}")
        return
    # åŠ è½½å‚æ•°ç½‘æ ¼
    param_grid = load_param_grid(args.config)
    # æ„é€ è¾“å‡ºæ–‡ä»¶å
    if args.output:
        output_file = args.output
    else:
        config_name = os.path.splitext(os.path.basename(args.config))[0]
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        output_file = f"outputs/data/{config_name}_metrics_{timestamp}.csv"
    out_dir = os.path.dirname(output_file)
    if out_dir:
        os.makedirs(out_dir, exist_ok=True)
    # è®¾ç½®ç¯å¢ƒå˜é‡ä¾›å¤šè¿›ç¨‹è®¿é—®
    os.environ['PIPELINE_TYPE'] = args.pipeline
    os.environ['ENABLE_RECV_CONGESTION'] = '1' if args.enable_recv_congestion else '0'
    generate_metrics(sim_module_name, output_file, param_grid, args.step)


if __name__ == '__main__':
    main()